{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get started with Redshift and the Feature Store\n",
    "\n",
    "This tutorial notebook will help you get started with working with the Hopsworks feature store and Redshift.\n",
    "\n",
    "\n",
    "* [Create security group for Redshift cluster](#sg_redhsift)\n",
    "* [Create a sample Amazon Redshift cluster](#setup_redhsift)\n",
    "* [Create AIM role for EC2 instance to access Redshift cluster](#aim_ec2_redhsift)\n",
    "* [Attach AIM role to your hopsworks cluster](#attach_aim_ec2)\n",
    "* [Load sample data into Redshift cluster](#load_data_redhsift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create security group for Redshift cluster <a name=\"sg_redhsift\"></a>\n",
    "\n",
    "\n",
    "### From AWS management console go to VPC\n",
    "\n",
    "![1.jpg](images/VPC_steps/1.jpg)\n",
    "\n",
    "\n",
    "## Choose security groups\n",
    "![2.jpg](images/VPC_steps/2.jpg)\n",
    "\n",
    "\n",
    "## Create security groups\n",
    "\n",
    "![3.jpg](images/VPC_steps/3.jpg)\n",
    "\n",
    "\n",
    "## Add inbound rules for Redshift cluster traffic \n",
    "\n",
    "![5.jpg](images/VPC_steps/5.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a sample Amazon Redshift cluster<a name=\"setup_redhsift\"></a>\n",
    "\n",
    "### Step 1) From AWS management console go to Redshift and select Create Cluster \n",
    "\n",
    "\n",
    "![1.jpg](images/redshift/1.png)\n",
    "\n",
    "\n",
    "### Step 2) From cluster configuration decide size of your Redshift cluster \n",
    "\n",
    "\n",
    "![2.jpg](images/redshift/2.png)\n",
    "\n",
    "\n",
    "### Step 3) Scroll down to Database Configuration and enter username and password\n",
    "\n",
    "![3.jpg](images/redshift/3.png)\n",
    "\n",
    "\n",
    "### Step 4) Scroll down to Cluster permissions. This is optional. However, you want to load data from S3 then you must give Redshift cluster AIM role that has S3 read policy\n",
    "\n",
    "\n",
    "![4.jpg](images/redshift/4.png)\n",
    "\n",
    "\n",
    "### Step 5) Scroll down Additional Configurations and add security group we created above \n",
    "\n",
    "![5.jpg](images/redshift/5.png)\n",
    "\n",
    "\n",
    "### Step 6) Scroll down and Create Cluster \n",
    "\n",
    "![6.jpg](images/redshift/6.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create AIM role for EC2 instance to access Redshift cluster <a name=\"aim_ec2_redhsift\"></a>\n",
    "\n",
    "\n",
    "## Step1 ) From AWS management console go to AIM Section\n",
    "\n",
    "![1.jpg](images/EC2_AIM/1.jpg)\n",
    "\n",
    "\n",
    "## Step2 ) Select roles\n",
    "\n",
    "![2.jpg](images/EC2_AIM/2.jpg)\n",
    "\n",
    "\n",
    "## Step3 ) Choose use case EC2\n",
    "\n",
    "![3.jpg](images/EC2_AIM/3.jpg)\n",
    "\n",
    "\n",
    "## Step4 ) Select necessary policy. For demo purposes we will select full access policy \n",
    "\n",
    "![4.jpg](images/EC2_AIM/4.jpg)\n",
    "\n",
    "\n",
    "## Step5 ) This step is optional. You tags empty\n",
    "\n",
    "![5.jpg](images/EC2_AIM/5.jpg)\n",
    "\n",
    "\n",
    "## Step6 ) In the final step create AIM role\n",
    "\n",
    "![6.jpg](images/EC2_AIM/6.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attach AIM role to your hopsworks cluster <a name=\"attach_aim_ec2\"></a>\n",
    "\n",
    "\n",
    "## Step 1) From AWS management console go to EC2\n",
    "\n",
    "![1.jpg](images/EC2_change_AIM/1.jpg)\n",
    "\n",
    "\n",
    "## Step 2) Select instances\n",
    "\n",
    "![2.jpg](images/EC2_change_AIM/2.jpg)\n",
    "\n",
    "\n",
    "## Step 3) Go to Actions and select Instance Settings and then Attach/Replace IAM Role\n",
    "\n",
    "![3.jpg](images/EC2_change_AIM/3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional dependencies\n",
    "[Download an Amazon Redshift JDBC driver](https://docs.aws.amazon.com/redshift/latest/mgmt/configure-jdbc-connection.html#download-jdbc-driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load  sample data into Redshift cluster <a name=\"load_data_redhsift\"></a>\n",
    "\n",
    "### Import a CSV in Redshift from s3 bucket\n",
    "\n",
    "Importing a CSV into Redshift requires you to create a table first. \n",
    "\n",
    "<code>\n",
    "    CREATE TABLE telcom (\n",
    "        customer_id VARCHAR primary key \n",
    "        gender VARCHAR,   \n",
    "        senior_citizen VARCHAR, \n",
    "        partner VARCHAR,\n",
    "        dependents VARCHAR,  \n",
    "        tenure INTEGER, \n",
    "        phone_service VARCHAR,      \n",
    "        multiple_lines VARCHAR, \n",
    "        internet_service VARCHAR, \n",
    "        online_security VARCHAR, \n",
    "        online_backup VARCHAR, \n",
    "        device_protection VARCHAR, \n",
    "        tech_support VARCHAR, \n",
    "        streaming_tv VARCHAR,\n",
    "        streaming_movies VARCHAR,        \n",
    "        contract VARCHAR,\n",
    "        paperless_billing VARCHAR,            \n",
    "        payment_method INTEGER, \n",
    "        monthly_charges INTEGER, \n",
    "        total_charges INTEGER, \n",
    "        churn VARCHAR    \n",
    "    );\n",
    "</code>\n",
    "\n",
    "and then copy\n",
    "\n",
    "<code>\n",
    "    COPY telcom\n",
    "        FROM 's3://<your-bucket-name>/load/file_name.csv'\n",
    "        credentials 'aws_access_key_id=<Your-Access-Key-ID>;aws_secret_access_key=<Your-Secret-Access-Key>'\n",
    "    CSV;\n",
    "</code>\n",
    "    \n",
    "please refer to the [Redshift COPY Command Specification](https://docs.aws.amazon.com/redshift/latest/dg/r_COPY.html) for a complete list of options for COPY,     \n",
    "\n",
    "    \n",
    "### Import a telcom data in Redshift from hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.api.java.JavaSparkContext;\n",
    "import org.apache.spark.sql.DataFrameWriter;\n",
    "import org.apache.spark.sql.Dataset;\n",
    "import org.apache.spark.sql.Row;\n",
    "import org.apache.spark.sql.SaveMode;\n",
    "import org.apache.spark.sql.SparkSession;\n",
    "import io.hops.util.Hops\n",
    "import org.apache.spark.sql._\n",
    "import spark.implicits._\n",
    "import org.apache.spark.sql.types._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val jdbcUsername = \"YOUR_REDSHIFT_USER_NAME\"\n",
    "val AIMrole = \"AIM_name_of_EC2_with_redshift_access\"\n",
    "val jdbcHostname = \"redshift-cluster-1.citpxgaovgkr.eu-north-1.redshift.amazonaws.com\"\n",
    "val jdbcPort = 5439\n",
    "val jdbcDatabase = \"telcom\"\n",
    "//val jdbcUrl = s\"jdbc:redshift://${jdbcHostname}:${jdbcPort}/${jdbcDatabase}\"\n",
    "val jdbcUrl = s\"jdbc:redshift:iam://${jdbcHostname}:${jdbcPort}/${jdbcDatabase}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telcom = spark.read.csv(\"path\")\n",
    "\n",
    "telcom\n",
    "  write.\n",
    "  format(\"jdbc\").\n",
    "  option(\"driver\", \"com.amazon.redshift.jdbc42.Driver\").\n",
    "  option(\"url\",jdbcUrl).\n",
    "  option(\"dbtable\", jdbcDatabase).\n",
    "  option(\"user\", jdbcUsername).\n",
    "  option(\"aws_iam_role\", AIMrole).\n",
    "  mode(\"append\"). \n",
    "  save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
